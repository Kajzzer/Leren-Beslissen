{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import cell :D\n",
    "''' \n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# test your pandas with this\n",
    "# pd.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the train and test data from the csv files\n",
    "'''\n",
    "\n",
    "# the train data and labels\n",
    "train_feat = pd.read_csv(\"train_feat.csv\")\n",
    "train_label = pd.read_csv(\"train_label.csv\")\n",
    "\n",
    "# the test data and labels\n",
    "test_feat = pd.read_csv(\"test_feat.csv\")\n",
    "test_label = pd.read_csv(\"test_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell for pandas understanding (1/3)\n",
    "''' \n",
    "\n",
    "# print the first 3 rows\n",
    "train_feat.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell for pandas understanding (2/3)\n",
    "''' \n",
    "\n",
    "# print the HR column\n",
    "train_feat.HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell for pandas understanding (3/3)\n",
    "''' \n",
    "\n",
    "# print the list of column names\n",
    "list(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove unmeasured metrics and the metrics that are given by the user\n",
    "\n",
    "@param  pandas DataFrame    The data\n",
    "@param  array               The list of metrics that need to be removed\n",
    "@return pandas DataFrame    The cleaned data\n",
    "'''\n",
    "def clean_data(d, metrics = []):\n",
    "    try:\n",
    "        # create a hard copy of the data\n",
    "        data = d.copy()\n",
    "\n",
    "        # get the unique values per column\n",
    "        unique_values = unique_vals(data)\n",
    "\n",
    "        # loop over all columns\n",
    "        for metric in data:\n",
    "            # check if we have a numeric or discrete metric, using the threshold\n",
    "            if unique_values.get(metric) == 1:\n",
    "                metrics.append(metric)\n",
    "                \n",
    "        # remove duplicates from the metrics list\n",
    "        # then remove those metrics from the data\n",
    "        return data.drop(columns=set(metrics))\n",
    "    except:\n",
    "        \n",
    "        # print a custom error message\n",
    "        print(\"The used list (\",metrics,\") contains column names that don't exist in the data.\")\n",
    "        \n",
    "        # return the original data\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "\n",
    "# clean the train data and print it\n",
    "train_cleaned = clean_data(train_feat, ['BRAmplitude', 'HRV', 'AuxADC1', 'AuxADC2', 'AuxADC3'])\n",
    "train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a csv with the averages of the data (per minute)\n",
    "\n",
    "@param  pandas DataFrame    The data (!including the Time column!)\n",
    "@param  string              The name of the target file\n",
    "'''\n",
    "def seconds_to_minutes(data,filename):\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "        \n",
    "    # open the (csv) file\n",
    "    f = open(filename, 'w+')\n",
    "\n",
    "    # initizalize the first line\n",
    "    line = \"\"\n",
    "\n",
    "    # create a line of the column names \n",
    "    for column in list(data):\n",
    "        line += column + \",\"\n",
    "    line = line[:-1] + \"\\n\"\n",
    "\n",
    "    # write the first line to the file\n",
    "    f.write(line)\n",
    "\n",
    "    # loop over the number of minutes\n",
    "    for i in range(0, int(len(data.index)),60):\n",
    "        \n",
    "        # get the minute of data out of the dataset\n",
    "        part = data.iloc[i:i+60]\n",
    "        \n",
    "        # calculate the means of the columns (as strings so pandas doesn't read everything as float64)\n",
    "        mean = part.mean().astype(str)\n",
    "        \n",
    "        # use the timestamp of the first second (as integer, remove the decimal)\n",
    "        mean.Time = str(data.iloc[i].Time)[:-2]\n",
    "\n",
    "        # reset the line\n",
    "        line = \"\"\n",
    "        \n",
    "        # create the line of values\n",
    "        for value in mean:\n",
    "            line += str(value) + \",\"\n",
    "        line = line[:-1] + \"\\n\"\n",
    "\n",
    "        # write the line to the file\n",
    "        f.write(line)\n",
    "        \n",
    "    # close the file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "\n",
    "# create the train data per minute csv file\n",
    "seconds_to_minutes(train_feat, \"train_feat_average.csv\")\n",
    "\n",
    "# create the test data per minute csv file\n",
    "seconds_to_minutes(test_feat, \"test_feat_average.csv\")\n",
    "\n",
    "\n",
    "# get the train feat per minute\n",
    "train_feat_average = pd.read_csv(\"train_feat_average.csv\")\n",
    "\n",
    "# get the test feat per minute\n",
    "test_feat_average = pd.read_csv(\"test_feat_average.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get the number of unique values of the metrics/columns\n",
    "\n",
    "@param  pandas DataFrame    The data\n",
    "@return int dict            The number of unique values per metric/column\n",
    "'''\n",
    "def unique_vals(data):\n",
    "    \n",
    "    # initialize the dictionary\n",
    "    unique_vals = dict()\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # use the set datastructure to remove duplicates and get the length of the set\n",
    "        unique_vals[metric] = len(set(train_feat[metric]))\n",
    "        \n",
    "    # return :D\n",
    "    return unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "\n",
    "# print the number of unique values for the train set\n",
    "print(unique_vals(train_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get the occurences of every value per metric\n",
    "\n",
    "@param  pandas DataFrame    The data\n",
    "@return Counter dict        The occurences of every value per metric \n",
    "'''\n",
    "def occurences(data):\n",
    "    \n",
    "    # the occurences datastructure\n",
    "    occ = defaultdict(Counter)\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # loop over the values \n",
    "        for value in data[metric]:\n",
    "            \n",
    "            # add the occurence\n",
    "            occ[metric][value] += 1\n",
    "    \n",
    "    # return :D\n",
    "    return occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "o = occurences(train_feat)\n",
    "\n",
    "#print\n",
    "print(o['HR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get the indices of the labels that match the activity\n",
    "\n",
    "@param  pandas DataFrame    The labels\n",
    "@param  string              The activity\n",
    "@return nparray             The indices of the rows that match the activity\n",
    "'''\n",
    "def get_indices(labels, activity):\n",
    "    \n",
    "    # get the indices of the rows that match the activity\n",
    "    # put them in a np array\n",
    "    return labels.index[labels['Label'] == activity].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the data of a specific activity\n",
    "@param  pandas DataFrame    The data\n",
    "@param  pandas DataFrame    The labels\n",
    "@param  string              The activity\n",
    "@return pandas DataFrame    The data that match the activity\n",
    "'''\n",
    "def data_of_activity(data, labels, activity):\n",
    "    \n",
    "    # get the indices of the labels that match the activity\n",
    "    indices = get_indices(labels, activity)\n",
    "    \n",
    "    # get the data of the indices\n",
    "    return data.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "\n",
    "# print the data of the towlift entries  \n",
    "data_of_activity(train_feat_average, train_label, \"towlift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Putting it all together in this cell\n",
    "'''\n",
    "\n",
    "# filename prefix (for the different datasets)\n",
    "# choose from : train, test, online_test\n",
    "prefix = 'train'\n",
    "\n",
    "# the filename of the completely preprocessed data\n",
    "result_filename = 'cleaned_'+ prefix + '_feat.csv'\n",
    "\n",
    "# the train data and labels\n",
    "feat = pd.read_csv(prefix + \"_feat.csv\")\n",
    "label = pd.read_csv(prefix + \"_label.csv\")\n",
    "\n",
    "# clean the data (except for Time)\n",
    "cleaned_feat = clean_data(feat, ['BRAmplitude', 'HRV', 'AuxADC1', 'AuxADC2', 'AuxADC3'])\n",
    "\n",
    "# create the data per minute csv file\n",
    "seconds_to_minutes(cleaned_feat, prefix + \"_feat_average.csv\")\n",
    "\n",
    "# get the feat per minute\n",
    "feat_average = pd.read_csv(prefix + \"_feat_average.csv\")\n",
    "\n",
    "cleaned_feat_average = clean_data(feat_average, ['Time'])\n",
    "\n",
    "# write the data to a csv\n",
    "cleaned_feat_average.to_csv(path_or_buf=result_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell is not needed, but you can add the labels to the data with this cell\n",
    "\n",
    "NOTE: Only do this when Time is still in the data\n",
    "'''\n",
    "\n",
    "# label = label.dropna(axis=1)\n",
    "\n",
    "# merge the data and labels on the Time metric\n",
    "merged = feat_average.merge(label, on='Time')\n",
    "\n",
    "# optional: remove Time from the data\n",
    "# merged = clean_data(merged, ['Time'])\n",
    "\n",
    "# write to a csv\n",
    "merged.to_csv('labeled_'+result_filename, index=False)\n",
    "\n",
    "# train data and labels combined\n",
    "labeled = pd.read_csv('labeled_'+result_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! IGNORE EVERYTHING BELOW FOR NOW !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data columns into descrete and numeric metrics, given a threshold\n",
    "def discrete_numeric_split(data, thres=10):\n",
    "    \n",
    "    # the datastructures\n",
    "    numeric = dict()\n",
    "    discrete = dict()\n",
    "    \n",
    "    # get the unique values\n",
    "    unique_values = unique_vals(data)\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # check if we have a numeric or discrete metric, using the threshold\n",
    "        if unique_values.get(metric) > thres:\n",
    "            numeric[metric] = data[metric]\n",
    "        else:\n",
    "            discrete[metric] = data[metric]\n",
    "    \n",
    "    # return :D\n",
    "    return discrete, numeric\n",
    "\n",
    "discrete, numeric = discrete_numeric_split(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(discrete),discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(numeric),numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ratio of the current activity\n",
    "def ratio(labels, activity):\n",
    "    \n",
    "    # get the total number of labels\n",
    "    total = len(labels)\n",
    "    \n",
    "    # check if we have labels\n",
    "    if total:\n",
    "        \n",
    "        # get the number of labels that are equal to our activity\n",
    "        activity_count = len([label for label in labels if label == activity])\n",
    "        \n",
    "        # return the ratio\n",
    "        return activity_count/total\n",
    "    \n",
    "    # no ratio, return zero\n",
    "    return 0\n",
    "\n",
    "\n",
    "# calculate the partial entropy\n",
    "def entropy_sub(p):\n",
    "    \n",
    "    # the log of 0 is NaN\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    \n",
    "    # return the p*log2(p)\n",
    "    return p*math.log(p,2)\n",
    "\n",
    "\n",
    "# calculate the entropy\n",
    "def entropy(labels):\n",
    "    \n",
    "    # initial entropy\n",
    "    e = 0\n",
    "    \n",
    "    # loop over the activities in the label list \n",
    "    for activity in list(set(labels)): \n",
    "        \n",
    "        # get the chance of the activity\n",
    "        p = ratio(labels, activity) \n",
    "        \n",
    "        # calculate the entropy of the current activity\n",
    "        e -= entropy_sub(p)-entropy_sub(1-p)\n",
    "    \n",
    "    # calculate the entropy\n",
    "    return e\n",
    "\n",
    "\n",
    "# calculate the entropy after a split \n",
    "def split_entropy(labels, indices, N):\n",
    "    \n",
    "    # initial entropy\n",
    "    e = 0\n",
    "    \n",
    "    # get the entropy after the split\n",
    "    for sub_indices in indices:\n",
    "        \n",
    "        # get the labels of the indices\n",
    "        sub_labels = [labels[index] for index in sub_indices if index < N] \n",
    "        \n",
    "        N_labels = len(sub_labels)\n",
    "        \n",
    "        # calculate the entropy after the split and normalise it\n",
    "        e += entropy(labels)\n",
    "        \n",
    "        # remove the current sub_labels\n",
    "        del sub_labels\n",
    "    \n",
    "    # return :D\n",
    "    return (N_labels/N)*e\n",
    "\n",
    "\n",
    "# calculate the information gain of the split\n",
    "def information_gain(label_data, indices):\n",
    "    \n",
    "    # get the list of labels\n",
    "    labels = label_data.Label\n",
    "    \n",
    "    # get the number of labels\n",
    "    total = len(labels)\n",
    "    \n",
    "    # get the entropy of the labels\n",
    "    e = entropy(labels)\n",
    "    \n",
    "    # get the entropy after the split\n",
    "    se = split_entropy(labels, indices, total)\n",
    "    \n",
    "    # return the information gain\n",
    "    return e - se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tests for me to check if the code worked\n",
    "e = entropy(train_label.Label)\n",
    "ig = information_gain(train_label, [[11, 22, 33, 44, 55, 66, 77, 88, 99, 111, 122, 133, 144, 155, 166, 177, 188, 199]])\n",
    "\n",
    "print(e,ig)\n",
    "\n",
    "#  {'Label': Counter({  'lift':         51,\n",
    "#                       'lying':        22,\n",
    "#                       'sitting':      58,\n",
    "#                       'snowboarding': 51,\n",
    "#                       'standing':     88    }),\n",
    "#\n",
    "#                       'total':        270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "     def __init__(self, discrete, numeric):\n",
    "        self.discrete = discrete\n",
    "        self.numeric = numeric\n",
    "        self.sd = len(discrete)\n",
    "        self.sn = len(numeric)\n",
    "        \n",
    "    def get_discrete(self, metric, index):\n",
    "        # get the discrete value of the index is valid\n",
    "        try:\n",
    "            return self.discrete[metric][index]\n",
    "        except:\n",
    "            return -1\n",
    "    \n",
    "    def get_numeric(self, metric, index):\n",
    "        # get the numeric value if the index is valid\n",
    "        try:\n",
    "            return self.numeric[metric][index]\n",
    "        except:\n",
    "            return -1\n",
    "        \n",
    "    def size_discrete(self):\n",
    "        # return the number of discrete variables\n",
    "        return self.sd\n",
    "    \n",
    "    def size_numeric(self):\n",
    "        # return the number of numeric variables\n",
    "        return self.sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
