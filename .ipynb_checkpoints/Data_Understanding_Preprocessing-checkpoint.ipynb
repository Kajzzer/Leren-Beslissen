{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import cell :D\n",
    "''' \n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# test your pandas with this\n",
    "# pd.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the train and test data from the csv files\n",
    "'''\n",
    "\n",
    "# the train data and labels\n",
    "train_feat = pd.read_csv(\"train_feat.csv\")\n",
    "train_label = pd.read_csv(\"train_label.csv\")\n",
    "\n",
    "# the test data and labels\n",
    "test_feat = pd.read_csv(\"test_feat.csv\")\n",
    "test_label = pd.read_csv(\"test_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell for pandas understanding (1/3)\n",
    "''' \n",
    "\n",
    "# print the first 3 rows\n",
    "train_feat.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell for pandas understanding (2/3)\n",
    "''' \n",
    "\n",
    "# print the HR column\n",
    "train_feat.HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell for pandas understanding (3/3)\n",
    "''' \n",
    "\n",
    "# print the list of column names\n",
    "list(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove unmeasured metrics and the metrics that are given by the user\n",
    "\n",
    "@param  pandas DataFrame    The data\n",
    "@param  array               The list of metrics that need to be removed\n",
    "@return pandas DataFrame    The cleaned data\n",
    "'''\n",
    "def clean_data(d, metrics = []):\n",
    "   \n",
    "    # create a hard copy of the data\n",
    "    data = d.copy()\n",
    "    \n",
    "    try:   \n",
    "        # get the unique values per column\n",
    "        unique_values = unique_vals(data)\n",
    "\n",
    "        # loop over all columns\n",
    "        for metric in data:\n",
    "            \n",
    "            # check if we have a numeric or discrete metric, using the threshold\n",
    "            if unique_values.get(metric) == 1:\n",
    "                metrics.append(metric)\n",
    "        \n",
    "        # remove duplicates from the metrics list\n",
    "        # then remove those metrics from the data\n",
    "        return data.drop(columns=set(metrics))\n",
    "    except:\n",
    "        \n",
    "        # print a custom error message\n",
    "        print(\"The used list (\",metrics,\") contains column names that don't exist in the data.\")\n",
    "        \n",
    "        # return the original data\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "\n",
    "# clean the train data and print it\n",
    "train_cleaned = clean_data(train_feat, ['BRAmplitude', 'HRV', 'AuxADC1', 'AuxADC2', 'AuxADC3'])\n",
    "train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a csv with the averages of the data (per minute)\n",
    "\n",
    "@param  pandas DataFrame    The data (!including the Time column!)\n",
    "@param  string              The name of the target file\n",
    "'''\n",
    "def seconds_to_minutes(data,filename):\n",
    "\n",
    "    # remove the file if it exists so we start with a clean file\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "        \n",
    "    # open the (csv) file\n",
    "    f = open(filename, 'w+')\n",
    "\n",
    "    # initizalize the first line\n",
    "    line = \"\"\n",
    "\n",
    "    # create a line of the column names \n",
    "    for column in list(data):\n",
    "        line += column + \",\"\n",
    "    line = line[:-1] + \"\\n\"\n",
    "\n",
    "    # write the first line to the file\n",
    "    f.write(line)\n",
    "\n",
    "    # loop over the number of minutes\n",
    "    for i in range(0, int(len(data.index)),60):\n",
    "        \n",
    "        # get the minute of data out of the dataset\n",
    "        part = data.iloc[i:i+60]\n",
    "        \n",
    "        # calculate the means of the columns (as strings so pandas doesn't read everything as float64)\n",
    "        mean = part.mean().astype(str)\n",
    "        \n",
    "        # use the timestamp of the first second (as integer, remove the decimal)\n",
    "        mean.Time = str(data.iloc[i].Time)[:-2]\n",
    "\n",
    "        # reset the line\n",
    "        line = \"\"\n",
    "        \n",
    "        # create the line of values\n",
    "        for value in mean:\n",
    "            line += str(value) + \",\"\n",
    "        line = line[:-1] + \"\\n\"\n",
    "\n",
    "        # write the line to the file\n",
    "        f.write(line)\n",
    "        \n",
    "    # close the file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "\n",
    "# create the train data per minute csv file\n",
    "seconds_to_minutes(train_feat, \"train_feat_average.csv\")\n",
    "\n",
    "# create the test data per minute csv file\n",
    "seconds_to_minutes(test_feat, \"test_feat_average.csv\")\n",
    "\n",
    "# get the train feat per minute\n",
    "train_feat_average = pd.read_csv(\"train_feat_average.csv\")\n",
    "\n",
    "# get the test feat per minute\n",
    "test_feat_average = pd.read_csv(\"test_feat_average.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get the number of unique values of the metrics/columns\n",
    "\n",
    "@param  pandas DataFrame    The data\n",
    "@return default dict        The number of unique values per metric/column\n",
    "'''\n",
    "def unique_vals(data):\n",
    "    \n",
    "    # initialize the dictionary\n",
    "    unique_vals = dict()\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # use the set datastructure to remove duplicates and get the length of the set\n",
    "        unique_vals[metric] = len(set(train_feat[metric]))\n",
    "        \n",
    "    # return :D\n",
    "    return unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "\n",
    "# print the number of unique values for the train set\n",
    "print(unique_vals(train_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get the occurences of every value per metric\n",
    "\n",
    "@param  pandas DataFrame    The data\n",
    "@return Counter dict        The occurences of every value per metric \n",
    "'''\n",
    "def occurences(data):\n",
    "    \n",
    "    # the occurences datastructure\n",
    "    occ = defaultdict(Counter)\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # loop over the values \n",
    "        for value in data[metric]:\n",
    "            \n",
    "            # add the occurence\n",
    "            occ[metric][value] += 1\n",
    "    \n",
    "    # return :D\n",
    "    return occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "o = occurences(train_feat)\n",
    "\n",
    "#print\n",
    "print(o['HR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get the indices of the labels that match the activity\n",
    "\n",
    "@param  pandas DataFrame    The labels\n",
    "@param  string              The activity\n",
    "@return nparray             The indices of the rows that match the activity\n",
    "'''\n",
    "def get_indices(labels, activity):\n",
    "    \n",
    "    # get the indices of the rows that match the activity\n",
    "    # put them in a np array\n",
    "    return labels.index[labels['Label'] == activity].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the data of a specific activity\n",
    "\n",
    "@param  pandas DataFrame    The data\n",
    "@param  pandas DataFrame    The labels\n",
    "@param  string              The activity\n",
    "@return pandas DataFrame    The data that match the activity\n",
    "'''\n",
    "def data_of_activity(data, labels, activity):\n",
    "    \n",
    "    # get the indices of the labels that match the activity\n",
    "    indices = get_indices(labels, activity)\n",
    "    \n",
    "    # get the data of the indices\n",
    "    return data.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test cell\n",
    "'''\n",
    "\n",
    "# print the data of the towlift entries  \n",
    "data_of_activity(train_feat_average, train_label, \"towlift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the beginning of the train set as the validation set (first 60 minutes)\n",
    "\n",
    "@param  pandas DataFrame    The train data\n",
    "@param  pandas DataFrame    The train labels\n",
    "@return pandas DataFrame    The splitted train data\n",
    "@return pandas DataFrame    The splitted validation data\n",
    "@return pandas DataFrame    The splitted train labels\n",
    "@return pandas DataFrame    The splitted validation labels\n",
    "'''\n",
    "def simple_split(data, labels):\n",
    "    \n",
    "    # get the validation part of the data\n",
    "    validation_feat = data.iloc[:3600]\n",
    "    \n",
    "    # get the train part of the data\n",
    "    train_feat = data.iloc[3600:]\n",
    "    \n",
    "    # get the validation part of the labels\n",
    "    validation_label = labels.iloc[:60]\n",
    "    \n",
    "    # get the train part of the labels\n",
    "    train_label = labels.iloc[60:]\n",
    "    \n",
    "    # return the splitted data and labels\n",
    "    return train_feat, validation_feat, train_label, validation_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the train and validation split of the train data\n",
    "\n",
    "@param  pandas DataFrame    The train data\n",
    "@param  pandas DataFrame    The train labels\n",
    "@param  boolean             Include all labels in the validation set\n",
    "'''\n",
    "def train_validation_split(data, labels, include_all = False):\n",
    "    \n",
    "    # check if we should include all the activities in the validation set\n",
    "    if not include_all:\n",
    "        train_feat, validation_feat, train_label, validation_label = simple_split(data, labels)\n",
    "    else:\n",
    "        print(\"Not implemented yet.\")\n",
    "        return\n",
    "        \n",
    "    # get the train part of the data\n",
    "    train_feat.to_csv(path_or_buf='train_split_feat.csv', index=False)\n",
    "    \n",
    "    # get the validation part of the data\n",
    "    validation_feat.to_csv(path_or_buf='validation_split_feat.csv', index=False)\n",
    "    \n",
    "    # get the train part of the labels\n",
    "    train_label.to_csv(path_or_buf='train_split_label.csv', index=False)\n",
    "    \n",
    "    # get the validation part of the labels\n",
    "    validation_label.to_csv(path_or_buf='validation_split_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the data\n",
    "\n",
    "@param  string    The data type (train, validation, test or online_test)\n",
    "@param  array     The metrics to remove\n",
    "@param  boolean   Include the time or not\n",
    "'''\n",
    "def preprocess_data_to_csv(data_type, metrics, remove_time):\n",
    "\n",
    "    # the filename of the completely preprocessed data\n",
    "    result_filename = 'preprocessed_'+ data_type + '_feat.csv'\n",
    "\n",
    "    # the train data and labels\n",
    "    feat = pd.read_csv(data_type + \"_feat.csv\")\n",
    "\n",
    "    # clean the data (except for Time)\n",
    "    cleaned_feat = clean_data(feat, metrics)\n",
    "\n",
    "    # create the data per minute csv file\n",
    "    seconds_to_minutes(cleaned_feat, data_type + \"_feat_average.csv\")\n",
    "\n",
    "    # get the feat per minute\n",
    "    feat_average = pd.read_csv(data_type + \"_feat_average.csv\")\n",
    "\n",
    "    # remove Time from the data, if we don't want to train on that\n",
    "    if (remove_time):\n",
    "        feat_average = clean_data(feat_average, ['Time'])\n",
    "\n",
    "    # write the data to a csv\n",
    "    feat_average.to_csv(path_or_buf=result_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess all the data and write it to a csv file for the ml models\n",
    "\n",
    "@param  array      The metrics to remove\n",
    "@param  boolean    Include the time or not\n",
    "'''\n",
    "def preprocess(metrics, remove_time = True):\n",
    "    \n",
    "    # the train data and labels\n",
    "    data = pd.read_csv(\"train_feat.csv\")\n",
    "    labels = pd.read_csv(\"train_label.csv\")\n",
    "    \n",
    "    # split the data and write it to csv files\n",
    "    train_validation_split(data, labels)\n",
    "    \n",
    "    # preprocess the train split of the data\n",
    "    preprocess_data_to_csv('train_split', metrics, remove_time)\n",
    "    \n",
    "    # preprocess the validation split of the data\n",
    "    preprocess_data_to_csv('validation_split', metrics, remove_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "preprocess(['BRAmplitude', 'HRV', 'AuxADC1', 'AuxADC2', 'AuxADC3'], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cells underneath are not needed, the preprocessing has already been completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Putting it all together in this cell\n",
    "# '''\n",
    "\n",
    "# # filename prefix (for the different datasets)\n",
    "# # choose from : train, test, online_test\n",
    "# prefix = 'train'\n",
    "\n",
    "# # the filename of the completely preprocessed data\n",
    "# result_filename = 'cleaned_'+ prefix + '_feat.csv'\n",
    "\n",
    "# # the train data and labels\n",
    "# feat = pd.read_csv(prefix + \"_feat.csv\")\n",
    "# label = pd.read_csv(prefix + \"_label.csv\")\n",
    "\n",
    "# # clean the data (except for Time)\n",
    "# cleaned_feat = clean_data(feat, ['BRAmplitude', 'HRV', 'AuxADC1', 'AuxADC2', 'AuxADC3'])\n",
    "\n",
    "# # create the data per minute csv file\n",
    "# seconds_to_minutes(cleaned_feat, prefix + \"_feat_average.csv\")\n",
    "\n",
    "# # get the feat per minute\n",
    "# feat_average = pd.read_csv(prefix + \"_feat_average.csv\")\n",
    "\n",
    "# # remove Time from the data, since we don't want to train on that\n",
    "# cleaned_feat_average = clean_data(feat_average, ['Time'])\n",
    "\n",
    "# # write the data to a csv\n",
    "# cleaned_feat_average.to_csv(path_or_buf=result_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# This cell is not needed, but you can add the labels to the data with this cell\n",
    "\n",
    "# NOTE: Only do this when Time is still in the data\n",
    "# '''\n",
    "\n",
    "# # merge the data and labels on the Time metric\n",
    "# merged = feat_average.merge(label, on='Time')\n",
    "\n",
    "# # optional: remove Time from the data\n",
    "# # merged = clean_data(merged, ['Time'])\n",
    "\n",
    "# # write to a csv\n",
    "# merged.to_csv('labeled_'+result_filename, index=False)\n",
    "\n",
    "# # train data and labels combined\n",
    "# labeled = pd.read_csv('labeled_'+result_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
