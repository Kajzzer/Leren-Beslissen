{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOPE\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# # Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "# x_data = np.random.rand(100).astype(np.float32)\n",
    "# y_data = x_data * 0.1 + 0.3\n",
    "# # Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# # (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# # figure that out for us.)\n",
    "# W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "# b = tf.Variable(tf.zeros([1]))\n",
    "# y = W * x_data + b\n",
    "# # Minimize the mean squared errors.\n",
    "# loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "# optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "# train = optimizer.minimize(loss)\n",
    "# # Before starting, initialize the variables.  We will 'run' this first.\n",
    "# init = tf.initialize_all_variables()\n",
    "# # Launch the graph.\n",
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "# # Fit the line.\n",
    "# for step in range(201):\n",
    "#     sess.run(train)\n",
    "#     if step % 20 == 0:\n",
    "#         print(step, sess.run(W), sess.run(b))\n",
    "# # Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOPE\n",
    "\n",
    "# '''Trains a simple deep NN on the MNIST dataset.\n",
    "# Gets to 98.40% test accuracy after 20 epochs\n",
    "# (there is *a lot* of margin for parameter tuning).\n",
    "# 2 seconds per epoch on a K520 GPU.\n",
    "# '''\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "# import keras\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.optimizers import RMSprop\n",
    "\n",
    "# batch_size = 128\n",
    "# num_classes = 10\n",
    "# epochs = 20\n",
    "\n",
    "# # the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# x_train = x_train.reshape(60000, 784)\n",
    "# x_test = x_test.reshape(10000, 784)\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=RMSprop(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(x_train, y_train,\n",
    "#                     batch_size=batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=(x_test, y_test))\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import block :D\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# pd.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the train data and labels\n",
    "train_feat = pd.read_csv(\"train_feat.csv\")\n",
    "train_label = pd.read_csv(\"train_label.csv\")\n",
    "\n",
    "\n",
    "# ! Not needed, kept it as a comment to be sure\n",
    "\n",
    "# label = label.dropna(axis=1)\n",
    "# merged = feat.merge(label, on='Time')\n",
    "# merged.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "# train data and labels combined\n",
    "# train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# !\n",
    "\n",
    "\n",
    "# get the unique values of the metrics\n",
    "def unique_vals(data):\n",
    "    \n",
    "    # the datastruture\n",
    "    unique_vals = dict()\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # recast to set to remove duplicates and get the length\n",
    "        unique_vals[metric] = len(set(train_feat[metric]))\n",
    "        \n",
    "    # return :D\n",
    "    return unique_vals\n",
    "\n",
    "def clean_data(d, metrics):\n",
    "    \n",
    "    # hard copy\n",
    "    data = d.copy()\n",
    "    \n",
    "    # get the unique values\n",
    "    unique_values = unique_vals(data)\n",
    "    \n",
    "    for metric in data:\n",
    "        # check if we have a numeric or discrete metric, using the threshold\n",
    "        if unique_values.get(metric) == 1:\n",
    "            metrics.append(metric)\n",
    "    return data.drop(columns=set(metrics))\n",
    "\n",
    "# train_feat\n",
    "train_feat = clean_data(train_feat, ['BRAmplitude', 'HRV', 'AuxADC1', 'AuxADC2', 'AuxADC3'])\n",
    "\n",
    "# the train feat per minute\n",
    "train_feat_average = pd.read_csv(\"train_feat_average.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_labels(data):\n",
    "    labels = []\n",
    "    for label in data:\n",
    "        if label == 'sitting':\n",
    "            labels.append(0)\n",
    "        elif label == 'lift':\n",
    "            labels.append(1)\n",
    "        elif label =='towlift':\n",
    "            labels.append(2)\n",
    "        elif label =='standing':\n",
    "            labels.append(3)\n",
    "        elif label =='lying':\n",
    "            labels.append(4)\n",
    "        elif label =='snowboarding':\n",
    "            labels.append(5)\n",
    "    return np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "X = train_feat_average\n",
    "y = numeric_labels(train_label.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 4., 4., 4., 4., 4., 4., 0., 0., 0., 0.,\n",
       "       0., 0., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 5., 5.,\n",
       "       5., 1., 1., 1., 1., 1., 1., 1., 5., 5., 5., 5., 5., 5., 5., 5., 1.,\n",
       "       1., 1., 5., 3., 3., 3., 3., 5., 5., 5., 5., 1., 1., 1., 1., 5., 5.,\n",
       "       5., 5., 5., 1., 1., 1., 1., 1., 3., 5., 5., 5., 5., 3., 1., 1., 1.,\n",
       "       5., 5., 5., 5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 5., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 5., 5., 5., 5., 5., 5., 1., 1., 1., 1.,\n",
       "       1., 1., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       2., 2., 2., 2., 3., 5., 5., 5., 5., 2., 2., 2., 2., 3., 3., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the train feat per minute\n",
    "test_feat_average = pd.read_csv(\"test_feat_average.csv\")\n",
    "test_label = pd.read_csv(\"test_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xt = test_feat_average\n",
    "predt = clf.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = numeric_labels(test_label.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.55555555555556 %\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for i in range(len(predt)):\n",
    "    total += 1\n",
    "    if predt[i] == control[i]:\n",
    "        correct += 1\n",
    "\n",
    "print('Accuracy:',correct*100/total,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X, y) \n",
    "\n",
    "predn = neigh.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.48148148148148 %\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for i in range(len(predn)):\n",
    "    total += 1\n",
    "    if predn[i] == control[i]:\n",
    "        correct += 1\n",
    "\n",
    "print('Accuracy:',correct*100/total,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
