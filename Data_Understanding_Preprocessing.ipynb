{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import block :D\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# pd.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the train data and labels\n",
    "train_feat = pd.read_csv(\"train_feat.csv\")\n",
    "train_label = pd.read_csv(\"train_label.csv\")\n",
    "\n",
    "\n",
    "# ! Not needed, kept it as a comment to be sure\n",
    "\n",
    "# label = label.dropna(axis=1)\n",
    "# merged = feat.merge(label, on='Time')\n",
    "# merged.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "# train data and labels combined\n",
    "# train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>HR</th>\n",
       "      <th>BR</th>\n",
       "      <th>SkinTemp</th>\n",
       "      <th>Posture</th>\n",
       "      <th>Activity</th>\n",
       "      <th>PeakAccel</th>\n",
       "      <th>BRAmplitude</th>\n",
       "      <th>BRNoise</th>\n",
       "      <th>BRConfidence</th>\n",
       "      <th>...</th>\n",
       "      <th>ROGTime</th>\n",
       "      <th>VerticalMin</th>\n",
       "      <th>VerticalPeak</th>\n",
       "      <th>LateralMin</th>\n",
       "      <th>LateralPeak</th>\n",
       "      <th>SagittalMin</th>\n",
       "      <th>SagittalPeak</th>\n",
       "      <th>AuxADC1</th>\n",
       "      <th>AuxADC2</th>\n",
       "      <th>AuxADC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1358759280432</td>\n",
       "      <td>101</td>\n",
       "      <td>18.6</td>\n",
       "      <td>-3276.8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>222</td>\n",
       "      <td>65535</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>0.31</td>\n",
       "      <td>427</td>\n",
       "      <td>441</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1358759281432</td>\n",
       "      <td>101</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-3276.8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.02</td>\n",
       "      <td>221</td>\n",
       "      <td>65535</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>430</td>\n",
       "      <td>444</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1358759282432</td>\n",
       "      <td>101</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-3276.8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.42</td>\n",
       "      <td>253</td>\n",
       "      <td>65535</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>431</td>\n",
       "      <td>444</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time   HR    BR  SkinTemp  Posture  Activity  PeakAccel  \\\n",
       "0  1358759280432  101  18.6   -3276.8       12      0.58       0.95   \n",
       "1  1358759281432  101  17.0   -3276.8       15      0.46       1.02   \n",
       "2  1358759282432  101  17.0   -3276.8       10      0.19       0.42   \n",
       "\n",
       "   BRAmplitude  BRNoise  BRConfidence   ...     ROGTime  VerticalMin  \\\n",
       "0          222    65535           255   ...          61        -1.20   \n",
       "1          221    65535           255   ...          62        -1.25   \n",
       "2          253    65535           255   ...          63        -1.18   \n",
       "\n",
       "   VerticalPeak  LateralMin  LateralPeak  SagittalMin  SagittalPeak  AuxADC1  \\\n",
       "0         -0.51       -0.15         0.72        -0.53          0.31      427   \n",
       "1         -0.39       -0.24         0.77        -0.71         -0.10      430   \n",
       "2         -0.83       -0.18         0.24        -0.31         -0.01      431   \n",
       "\n",
       "   AuxADC2  AuxADC3  \n",
       "0      441      515  \n",
       "1      444      516  \n",
       "2      444      517  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the train data\n",
    "train_feat.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv with the averages of the data (per minute)\n",
    "def seconds_to_minutes(data,filename):\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "        \n",
    "    # open the (csv) file\n",
    "    f = open(filename, 'w+')\n",
    "\n",
    "    # initizalize the first line\n",
    "    line = \"\"\n",
    "\n",
    "    # create a line of the column names \n",
    "    for column in list(data):\n",
    "        line += column + \",\"\n",
    "    line = line[:-1] + \"\\n\"\n",
    "\n",
    "    # write the first line to the file\n",
    "    f.write(line)\n",
    "\n",
    "    # loop over the number of minutes\n",
    "    for i in range(int(len(data.index)/60)):\n",
    "        \n",
    "        # minute iterators \n",
    "        j = i*60\n",
    "        \n",
    "        # get the minute of data out of the dataset\n",
    "        part = data.iloc[j:j+60]\n",
    "        \n",
    "        # calculate the means of the columns (as strings so pandas doesn't read everything as float64)\n",
    "        mean = part.mean().astype(str)\n",
    "        \n",
    "        # use the timestamp of the first second (as integer, remove the decimal)\n",
    "        mean.Time = str(data.iloc[j].Time)[:-2]\n",
    "\n",
    "        # reset the line\n",
    "        line = \"\"\n",
    "        \n",
    "        # create the line of values\n",
    "        for value in mean:\n",
    "            line += str(value) + \",\"\n",
    "        line = line[:-1] + \"\\n\"\n",
    "\n",
    "        # write the line to the file\n",
    "        f.write(line)\n",
    "        \n",
    "    # close the file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_to_minutes(train_feat, \"train_feat_average.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the train feat per minute\n",
    "train_feat_average = pd.read_csv(\"train_feat_average.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>HR</th>\n",
       "      <th>BR</th>\n",
       "      <th>SkinTemp</th>\n",
       "      <th>Posture</th>\n",
       "      <th>Activity</th>\n",
       "      <th>PeakAccel</th>\n",
       "      <th>BRAmplitude</th>\n",
       "      <th>BRNoise</th>\n",
       "      <th>BRConfidence</th>\n",
       "      <th>...</th>\n",
       "      <th>ROGTime</th>\n",
       "      <th>VerticalMin</th>\n",
       "      <th>VerticalPeak</th>\n",
       "      <th>LateralMin</th>\n",
       "      <th>LateralPeak</th>\n",
       "      <th>SagittalMin</th>\n",
       "      <th>SagittalPeak</th>\n",
       "      <th>AuxADC1</th>\n",
       "      <th>AuxADC2</th>\n",
       "      <th>AuxADC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1358759280432</td>\n",
       "      <td>97.466667</td>\n",
       "      <td>13.995000</td>\n",
       "      <td>-3276.8</td>\n",
       "      <td>27.350000</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>129.816667</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.5</td>\n",
       "      <td>-0.878000</td>\n",
       "      <td>-0.673167</td>\n",
       "      <td>-0.057667</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>-0.486167</td>\n",
       "      <td>-0.269333</td>\n",
       "      <td>435.600000</td>\n",
       "      <td>452.433333</td>\n",
       "      <td>518.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1358759340432</td>\n",
       "      <td>92.250000</td>\n",
       "      <td>14.836667</td>\n",
       "      <td>-3276.8</td>\n",
       "      <td>14.150000</td>\n",
       "      <td>0.108667</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>90.466667</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>150.5</td>\n",
       "      <td>-0.884000</td>\n",
       "      <td>-0.742000</td>\n",
       "      <td>-0.051833</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>-0.249333</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>427.433333</td>\n",
       "      <td>440.666667</td>\n",
       "      <td>515.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1358759400432</td>\n",
       "      <td>91.833333</td>\n",
       "      <td>13.843333</td>\n",
       "      <td>-3276.8</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.199167</td>\n",
       "      <td>88.600000</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>210.5</td>\n",
       "      <td>-1.066167</td>\n",
       "      <td>-0.906667</td>\n",
       "      <td>-0.048500</td>\n",
       "      <td>0.159333</td>\n",
       "      <td>-0.069500</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>424.816667</td>\n",
       "      <td>436.283333</td>\n",
       "      <td>513.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         HR         BR  SkinTemp    Posture  Activity  \\\n",
       "0  1358759280432  97.466667  13.995000   -3276.8  27.350000  0.122000   \n",
       "1  1358759340432  92.250000  14.836667   -3276.8  14.150000  0.108667   \n",
       "2  1358759400432  91.833333  13.843333   -3276.8  -1.166667  0.113000   \n",
       "\n",
       "   PeakAccel  BRAmplitude  BRNoise  BRConfidence     ...      ROGTime  \\\n",
       "0   0.230000   129.816667  65535.0         255.0     ...         90.5   \n",
       "1   0.207500    90.466667  65535.0         255.0     ...        150.5   \n",
       "2   0.199167    88.600000  65535.0         255.0     ...        210.5   \n",
       "\n",
       "   VerticalMin  VerticalPeak  LateralMin  LateralPeak  SagittalMin  \\\n",
       "0    -0.878000     -0.673167   -0.057667     0.126000    -0.486167   \n",
       "1    -0.884000     -0.742000   -0.051833     0.086500    -0.249333   \n",
       "2    -1.066167     -0.906667   -0.048500     0.159333    -0.069500   \n",
       "\n",
       "   SagittalPeak     AuxADC1     AuxADC2     AuxADC3  \n",
       "0     -0.269333  435.600000  452.433333  518.533333  \n",
       "1     -0.103000  427.433333  440.666667  515.133333  \n",
       "2      0.132833  424.816667  436.283333  513.150000  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first 3 rows\n",
    "train_feat_average.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        101\n",
       "1        101\n",
       "2        101\n",
       "3        102\n",
       "4        103\n",
       "5        104\n",
       "6        105\n",
       "7        106\n",
       "8        107\n",
       "9        106\n",
       "10       107\n",
       "11       108\n",
       "12       108\n",
       "13       109\n",
       "14       109\n",
       "15       109\n",
       "16       109\n",
       "17       106\n",
       "18       103\n",
       "19        99\n",
       "20        98\n",
       "21        97\n",
       "22        96\n",
       "23        97\n",
       "24        95\n",
       "25        93\n",
       "26        92\n",
       "27        89\n",
       "28        89\n",
       "29        91\n",
       "        ... \n",
       "16170    142\n",
       "16171    142\n",
       "16172    143\n",
       "16173    148\n",
       "16174    153\n",
       "16175    155\n",
       "16176    155\n",
       "16177    155\n",
       "16178    156\n",
       "16179    156\n",
       "16180    156\n",
       "16181    157\n",
       "16182    156\n",
       "16183    156\n",
       "16184    155\n",
       "16185    154\n",
       "16186    152\n",
       "16187    151\n",
       "16188    151\n",
       "16189    151\n",
       "16190    151\n",
       "16191    150\n",
       "16192    151\n",
       "16193    152\n",
       "16194    151\n",
       "16195    151\n",
       "16196    150\n",
       "16197    148\n",
       "16198    147\n",
       "16199    148\n",
       "Name: HR, Length: 16200, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a column (HR for example)\n",
    "train_feat.HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Activity': 97,\n",
       " 'AuxADC1': 265,\n",
       " 'AuxADC2': 332,\n",
       " 'AuxADC3': 154,\n",
       " 'BR': 327,\n",
       " 'BRAmplitude': 428,\n",
       " 'BRConfidence': 1,\n",
       " 'BRNoise': 1,\n",
       " 'ECGAmplitude': 161,\n",
       " 'ECGNoise': 168,\n",
       " 'GSR': 1,\n",
       " 'HR': 142,\n",
       " 'HRConfidence': 91,\n",
       " 'HRV': 103,\n",
       " 'LateralMin': 128,\n",
       " 'LateralPeak': 114,\n",
       " 'PeakAccel': 166,\n",
       " 'Posture': 152,\n",
       " 'ROGState': 4,\n",
       " 'ROGTime': 2099,\n",
       " 'SagittalMin': 215,\n",
       " 'SagittalPeak': 193,\n",
       " 'SkinTemp': 1,\n",
       " 'Time': 16200,\n",
       " 'VerticalMin': 235,\n",
       " 'VerticalPeak': 121}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the unique values of the metrics\n",
    "def unique_vals(data):\n",
    "    \n",
    "    # the datastruture\n",
    "    unique_vals = dict()\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # recast to set to remove duplicates and get the length\n",
    "        unique_vals[metric] = len(set(train_feat[metric]))\n",
    "        \n",
    "    # return :D\n",
    "    return unique_vals\n",
    "\n",
    "unique_vals(train_feat)\n",
    "# for metric in train_feat:\n",
    "#     print(\"Number of unique values of \",metric,\": \",len(list(set(train_feat[metric]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1, 1: 12925, 2: 448, 3: 2826})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the occurences value of every metric\n",
    "def occurences(data):\n",
    "    \n",
    "    # the occurences datastructure\n",
    "    occurences = defaultdict(Counter)\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # loop over the values \n",
    "        for value in data[metric]:\n",
    "            \n",
    "            # add the occurence\n",
    "            occurences[metric][value] += 1\n",
    "    \n",
    "    # return :D\n",
    "    return occurences\n",
    "\n",
    "occurences = occurences(train_feat)\n",
    "occurences['ROGState']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the indices of the labels that match the activity\n",
    "def get_indices(labels, activity):\n",
    "    return labels.index[labels['Label'] == activity].tolist()\n",
    "\n",
    "# get the data of a specific activity\n",
    "def data_of_activity(data, labels, activity):\n",
    "    \n",
    "    # get the indices of the labels of the activity\n",
    "    indices = get_indices(labels, activity)\n",
    "    \n",
    "    # get the data of the indices\n",
    "    return data.iloc[indices]\n",
    "\n",
    "# test\n",
    "data_of_activity(train_feat_average, train_label, \"sitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data columns into descrete and numeric metrics, given a threshold\n",
    "def discrete_numeric_split(data, thres=10):\n",
    "    \n",
    "    # the datastructures\n",
    "    numeric = dict()\n",
    "    discrete = dict()\n",
    "    \n",
    "    # get the unique values\n",
    "    unique_values = unique_vals(data)\n",
    "    \n",
    "    # loop over the metrics\n",
    "    for metric in data:\n",
    "        \n",
    "        # check if we have a numeric or discrete metric, using the threshold\n",
    "        if unique_values.get(metric) > thres:\n",
    "            numeric[metric] = data[metric]\n",
    "        else:\n",
    "            discrete[metric] = data[metric]\n",
    "    \n",
    "    # return :D\n",
    "    return discrete, numeric\n",
    "\n",
    "discrete, numeric = discrete_numeric_split(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(discrete),discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(numeric),numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ratio of the current activity\n",
    "def ratio(labels, activity):\n",
    "    \n",
    "    # get the total number of labels\n",
    "    total = len(labels)\n",
    "    \n",
    "    # check if we have labels\n",
    "    if total:\n",
    "        \n",
    "        # get the number of labels that are equal to our activity\n",
    "        activity_count = len([label for label in labels if label == activity])\n",
    "        \n",
    "        # return the ratio\n",
    "        return activity_count/total\n",
    "    \n",
    "    # no ratio, return zero\n",
    "    return 0\n",
    "\n",
    "\n",
    "# calculate the partial entropy\n",
    "def entropy_sub(p):\n",
    "    \n",
    "    # the log of 0 is NaN\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    \n",
    "    # return the p*log2(p)\n",
    "    return p*math.log(p,2)\n",
    "\n",
    "\n",
    "# calculate the entropy\n",
    "def entropy(labels):\n",
    "    \n",
    "    # initial entropy\n",
    "    e = 0\n",
    "    \n",
    "    # loop over the activities in the label list \n",
    "    for activity in list(set(labels)): \n",
    "        \n",
    "        # get the chance of the activity\n",
    "        p = ratio(labels, activity) \n",
    "        \n",
    "        # calculate the entropy of the current activity\n",
    "        e -= entropy_sub(p)-entropy_sub(1-p)\n",
    "    \n",
    "    # calculate the entropy\n",
    "    return e\n",
    "\n",
    "\n",
    "# calculate the entropy after a split \n",
    "def split_entropy(labels, indices, N):\n",
    "    \n",
    "    # initial entropy\n",
    "    e = 0\n",
    "    \n",
    "    # get the entropy after the split\n",
    "    for sub_indices in indices:\n",
    "        \n",
    "        # get the labels of the indices\n",
    "        sub_labels = [labels[index] for index in sub_indices if index < N] \n",
    "        \n",
    "        N_labels = len(sub_labels)\n",
    "        \n",
    "        # calculate the entropy after the split and normalise it\n",
    "        e += entropy(labels)\n",
    "        \n",
    "        # remove the current sub_labels\n",
    "        del sub_labels\n",
    "    \n",
    "    # return :D\n",
    "    return (N_labels/N)*e\n",
    "\n",
    "\n",
    "# calculate the information gain of the split\n",
    "def information_gain(label_data, indices):\n",
    "    \n",
    "    # get the list of labels\n",
    "    labels = label_data.Label\n",
    "    \n",
    "    # get the number of labels\n",
    "    total = len(labels)\n",
    "    \n",
    "    # get the entropy of the labels\n",
    "    e = entropy(labels)\n",
    "    \n",
    "    # get the entropy after the split\n",
    "    se = split_entropy(labels, indices, total)\n",
    "    \n",
    "    # return the information gain\n",
    "    return e - se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tests for me to check if the code worked\n",
    "e = entropy(train_label.Label)\n",
    "ig = information_gain(train_label, [[11, 22, 33, 44, 55, 66, 77, 88, 99, 111, 122, 133, 144, 155, 166, 177, 188, 199]])\n",
    "\n",
    "print(e,ig)\n",
    "\n",
    "#  {'Label': Counter({  'lift':         51,\n",
    "#                       'lying':        22,\n",
    "#                       'sitting':      58,\n",
    "#                       'snowboarding': 51,\n",
    "#                       'standing':     88    }),\n",
    "#\n",
    "#                       'total':        270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "     def __init__(self, discrete, numeric):\n",
    "        self.discrete = discrete\n",
    "        self.numeric = numeric\n",
    "        self.sd = len(discrete)\n",
    "        self.sn = len(numeric)\n",
    "        \n",
    "    def get_discrete(self, metric, index):\n",
    "        # get the discrete value of the index is valid\n",
    "        try:\n",
    "            return self.discrete[metric][index]\n",
    "        except:\n",
    "            return -1\n",
    "    \n",
    "    def get_numeric(self, metric, index):\n",
    "        # get the numeric value if the index is valid\n",
    "        try:\n",
    "            return self.numeric[metric][index]\n",
    "        except:\n",
    "            return -1\n",
    "        \n",
    "    def size_discrete(self):\n",
    "        # return the number of discrete variables\n",
    "        return self.sd\n",
    "    \n",
    "    def size_numeric(self):\n",
    "        # return the number of numeric variables\n",
    "        return self.sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, data, labels, tree_type=0, thres=0.1):\n",
    "        \"\"\" Creates a Decision Tree, based on the following arguments:\n",
    "                data - An array of DataRow objects, each instance containing\n",
    "                        the discrete and numeric data for one patient\n",
    "                labels - An array of boolean class labels, each corresponding to a\n",
    "                        DataRow instance of a patient at the same index. \n",
    "                tree_type - 0: create the Tree with the highest IG every node \n",
    "                            1: create DiscreteTrees only\n",
    "                            2: create NumericTrees only\n",
    "                thres - The cutoff value for IG, to stop splitting the tree.\n",
    "                        Below this value the node becomes a leaf node and no\n",
    "                        further splits are made.\n",
    "            N.B. This function has already been provided and does not need to be\n",
    "            modified.\"\"\"\n",
    "        \n",
    "        # Store the basic attributes for any DecisionTree\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.tree_type = tree_type\n",
    "        self.thres = thres\n",
    "        \n",
    "        # Compute the current ratio of labels and assign this node the most common label\n",
    "        self.ratio = ratio(self.labels)\n",
    "        self.label = self.ratio >= 0.5\n",
    "        \n",
    "        if self.tree_type == 1:\n",
    "            # Convert this DecisionTree to a DiscreteTree and perform the split\n",
    "            discr_tree = DiscreteTree(self)\n",
    "            self.convert_tree(discr_tree)\n",
    "        elif self.tree_type == 2:\n",
    "            # Convert this DecisionTree to a NumericTree and perform the split\n",
    "            numer_tree = NumericTree(self)\n",
    "            self.convert_tree(numer_tree)\n",
    "        else:\n",
    "            # Create a DiscreteTree and NumericTree, passing all the stored attributes\n",
    "            # as an argument, and compute the best possible split for each\n",
    "            discr_tree = DiscreteTree(self)\n",
    "            numer_tree = NumericTree(self)\n",
    "            \n",
    "            # Based on the results of the split computations, replace this generic\n",
    "            # DecisionTree node with either a DiscreteTree or a NumericTree node\n",
    "            if discr_tree.info_gain > numer_tree.info_gain:\n",
    "                self.convert_tree(discr_tree)\n",
    "            else:\n",
    "                self.convert_tree(numer_tree)\n",
    "        \n",
    "        # Create an empty dictionary to contain the (possible) branches from this node,\n",
    "        # where the values should be new DecisionTree nodes, or None if not present\n",
    "        self.branches = defaultdict(lambda: None)\n",
    "        \n",
    "        # Check if this split produced a high enough Information Gain to actually create\n",
    "        # the resulting branches with new split nodes below it, else this is a leaf node\n",
    "        self.leaf = self.info_gain < self.thres\n",
    "        if not self.leaf:\n",
    "            self.create_subtrees()\n",
    "    \n",
    "    def store_split_values(self, var_index, var_values, indices, info_gain):\n",
    "        \"\"\" Stores the values of the passed parameters as object attributes. Is intended\n",
    "            to store the results of a split computation for either a DiscreteTree or a\n",
    "            NumericTree. The stored attributes are:\n",
    "                var_index - The DataRow index of the variable on which the split was\n",
    "                    based.\n",
    "                var_values - A list of the possible values that this split variable can\n",
    "                    take, each corresponding to a different branch in the DecisionTree\n",
    "                indices - A list of index lists, with each list containing the indices\n",
    "                    defining a subset of the current data and label attributes, as\n",
    "                    computed by the split. The order of these subsets should match the\n",
    "                    order of the corresponding var_values used to define the branches\n",
    "                    of the split.\n",
    "                info_gain - Information Gain computed for this split\n",
    "            N.B. This function has already been provided and does not need to be\n",
    "            modified.\"\"\"\n",
    "        self.var_index = var_index\n",
    "        self.var_values = var_values\n",
    "        self.indices = indices\n",
    "        self.info_gain = info_gain\n",
    "    \n",
    "    def convert_tree(self, new_tree):\n",
    "        \"\"\" Converts this object to the tree passed as the new_tree parameter.\n",
    "            All attributes from the new_tree are transfered.\n",
    "                new_tree - Either a DiscreteTree or a NumericTree instance, to which\n",
    "                            this object is converted\n",
    "            N.B. This function has already been provided and does not need to be\n",
    "            modified.\"\"\"\n",
    "        self.__class__ = new_tree.__class__\n",
    "        self.__dict__ = new_tree.__dict__\n",
    "    \n",
    "    def create_subtrees(self):\n",
    "        \"\"\" Creates the different subsets of the current data and labels, and makes a\n",
    "            a new DecisionTree node for each such subset, based on the indices attribute\n",
    "            stored after the computed split. These new DecisionTrees are stored in the \n",
    "            branches attribute, a dictionary mapping the value of a variable from the\n",
    "            split to the new DecisionTree created by selecting that value for the split.\"\"\"\n",
    "\n",
    "        # loop over the values of the variable\n",
    "        for metric in self.data:\n",
    "            \n",
    "            # (re)set the lists\n",
    "            sub_data = []\n",
    "            sub_labels = []\n",
    "            \n",
    "            # loop over the indices of that variable value and build the lists\n",
    "            for index in self.indices[value_index]:\n",
    "                sub_data.append(self.data[index]) \n",
    "                sub_labels.append(self.labels[index])\n",
    "        \n",
    "            # create the branch\n",
    "            self.branches[self.var_values[value_index]] = DecisionTree(sub_data, sub_labels, self.tree_type, self.thres)\n",
    "        \n",
    "        \n",
    "    def classify(self, row):\n",
    "        \"\"\" Traverses the DecisionTree based on the values stored in the data row and\n",
    "            returns the most common label in the resulting leaf node.\n",
    "                row - The DataRow object containing the values that are being\n",
    "                        classified\"\"\"\n",
    "        \n",
    "        # get the subtree or None\n",
    "        subtree = self.get_subtree(row)\n",
    "        \n",
    "        # classify the row for the subtree\n",
    "        if subtree:\n",
    "            return subtree.classify(row)\n",
    "        \n",
    "        # use this tree for the classification\n",
    "        else:\n",
    "            \n",
    "            # this is the leaf node, check is the 1 label is more common\n",
    "            if sum(self.labels)/len(self.labels) >= 0.5:\n",
    "                return 1.0\n",
    "\n",
    "            # the 0 label is more common\n",
    "            else:\n",
    "                return 0.0\n",
    "    \n",
    "    def validate(self, data, labels):\n",
    "        \"\"\" Classifies all the DataRow instances in data and compares the outcome to \n",
    "            the provided labels. Returns the percentage of elements that was classified\n",
    "            correctly.\n",
    "                data - List of DataRow instances to be classified.\n",
    "                labels - List of boolean labels each belonging to a DataRow instances at\n",
    "                    the same index\"\"\"\n",
    "        \n",
    "        total = len(data)\n",
    "        correct = 0\n",
    "        \n",
    "        # loop over all lables\n",
    "        for index in range(total):\n",
    "            \n",
    "            # get the label of the current index\n",
    "            label = self.classify(data[index]) \n",
    "            \n",
    "            # match the label\n",
    "            if label == labels[index]:\n",
    "                \n",
    "                # mark as correct\n",
    "                correct += 1\n",
    "                \n",
    "        return 100*correct/total \n",
    "        \n",
    "        \n",
    "    def split(self):\n",
    "        \"\"\" Must be implemented by the subclass based on the specific type of split performed.\n",
    "            The function here is only to ensure it is implemented, and should not be modified.\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_subtree(self, instance):\n",
    "        \"\"\" Must be implemented by the subclass based on the specific type of split performed.\n",
    "            The function here is only to ensure it is implemented, and should not be modified.\"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteTree(DecisionTree):\n",
    "    def __init__(self, dtree):\n",
    "        \"\"\" Takes a DecisionTree as initialization parameter and copies all its\n",
    "            attributes. Then calls the split() function to determine the optimal\n",
    "            discrete variable to split this subset of the data on.\n",
    "                dtree - The DecisionTree instance whose attributes are copied to this\n",
    "                        DiscreteTree instance.\n",
    "            N.B. This function has already been provided and does not need to be\n",
    "            modified.\"\"\"\n",
    "        self.__dict__ = dtree.__dict__.copy()\n",
    "        self.split()\n",
    "\n",
    "    def split(self):\n",
    "        \"\"\" Determines the best discrete variable to split the current dataset on,\n",
    "            based on the IG resulting from the split. For this best split variable, the\n",
    "            function stores several resulting attributes from the split, using the\n",
    "            store_split_values function. See the documentation of store_split_values\n",
    "            for an overview of what should be stored.\"\"\"\n",
    "        \n",
    "        # initial gain (-1 instead of 0 so that we set the info_gain at least once)\n",
    "        highest_gain = -1;\n",
    "        \n",
    "        # the total number of discrete variables \n",
    "        total_vars = self.data[0].size_discrete()\n",
    "        \n",
    "        # for every column\n",
    "        for var_index in range(total_vars):\n",
    "            \n",
    "            # create the column\n",
    "            column = DataColumn(var_index)\n",
    "            \n",
    "            # for every row\n",
    "            for row_index in range(len(self.data)):\n",
    "                \n",
    "                # get the DataRow object\n",
    "                row = self.data[row_index]\n",
    "                \n",
    "                # add the row index and value to the column\n",
    "                value = row.get_discrete(var_index)\n",
    "                column.add(row_index, value)\n",
    "            \n",
    "            # (re)set the values\n",
    "            info_gain = 0\n",
    "            indices = []\n",
    "            var_values = []\n",
    "            \n",
    "            # for every unique value in column\n",
    "            for unique_value in column.unique_values:\n",
    "                \n",
    "                # for all rows with that value create indices list\n",
    "                sub_indices = [row.index for row in column.entries if row.value == unique_value]        \n",
    "                \n",
    "                indices.append(sub_indices)\n",
    "                var_values.append(unique_value)\n",
    "                \n",
    "                # calculate information gain\n",
    "                info_gain = information_gain(self.labels, indices)\n",
    "                \n",
    "            # store the entropy if its the one with the highest gain\n",
    "            if info_gain > highest_gain:\n",
    "                self.store_split_values(var_index, var_values, indices, info_gain)\n",
    "                highest_gain = info_gain\n",
    "            \n",
    "            # remove the column from our memory\n",
    "            del column\n",
    "                \n",
    "            \n",
    "    def get_subtree(self, row):\n",
    "        \"\"\" Returns the subtree one branch down, corresponding the to value of\n",
    "            variable in the DataRow for specific variable based on which the split\n",
    "            at this node was performed.\n",
    "            Returns None if the value was not present at the split.\n",
    "                row - The DataRow object containing the values that are being\n",
    "                        classified\"\"\"\n",
    "        \n",
    "        # get the value of the correct column\n",
    "        value = row.get_discrete(self.var_index)\n",
    "        \n",
    "        # get the branch of that value\n",
    "        try:\n",
    "            return self.branches[value]\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericTree(DecisionTree):\n",
    "    def __init__(self, dtree):\n",
    "        \"\"\" Takes a DecisionTree as initialization parameter and copies all its\n",
    "            attributes. Then calls the split() function to determine the optimal\n",
    "            numeric variable to split this subset of the data on.\n",
    "                dtree - The DecisionTree instance whose attributes are copied to this\n",
    "                        NumericTree instance.\n",
    "            N.B. This function has already been provided and does not need to be\n",
    "            modified.\"\"\"\n",
    "        self.__dict__ = dtree.__dict__.copy()\n",
    "        self.split()\n",
    "\n",
    "    def split(self):\n",
    "        \"\"\" Determines the best boundary for any numeric variable to split the\n",
    "            current dataset on, based on the IG resulting from the split. For this\n",
    "            best split boundary, the function stores several resulting attributes\n",
    "            from the split, using the store_split_values function. See the\n",
    "            documentation of store_split_values for an overview of what should\n",
    "            be stored. In addition, one more attribute is stored in the numeric\n",
    "            case, namely the boundary value used for the split.\"\"\"\n",
    "        \n",
    "         # initial gain (-1 instead of 0 so that we set the info_gain at least once)\n",
    "        highest_gain = -1;\n",
    "        \n",
    "        # the total number of discrete variables \n",
    "        total_vars = self.data[0].size_numeric()\n",
    "        \n",
    "        # for every column\n",
    "        for var_index in range(total_vars):\n",
    "            \n",
    "            # create the column\n",
    "            column = DataColumn(var_index)\n",
    "            \n",
    "            # for every row\n",
    "            for row_index in range(len(self.data)):\n",
    "                \n",
    "                # get the DataRow object\n",
    "                row = self.data[row_index]\n",
    "                \n",
    "                # add the row index and value to the column\n",
    "                value = row.get_numeric(var_index)\n",
    "                column.add(row_index, value)\n",
    "            \n",
    "            # the var values     \n",
    "            # NOTE:  This was the bug... I had var_values = ['bigger', 'smaller'] but I add the indices that \n",
    "            #        have a smaller value first. So it ALWAYS picked the wrong branch \n",
    "            #        and still had an accuracy of over 50% \n",
    "            var_values = ['smaller', 'bigger']\n",
    "            \n",
    "            # for every unique value in column\n",
    "            for unique_value in column.unique_values:\n",
    "                \n",
    "                # (re)set the values\n",
    "                info_gain = 0\n",
    "                indices = []\n",
    "                \n",
    "                # get the indices that are smaller (or bigger of the second line) than the current unique value \n",
    "                smaller_indices = [row.index for row in column.entries if row.value < unique_value]\n",
    "                bigger_indices = [row.index for row in column.entries if row.value >= unique_value]   \n",
    "                \n",
    "                # add the sub indices to the total\n",
    "                indices.append(smaller_indices)\n",
    "                indices.append(bigger_indices)\n",
    "                \n",
    "                info_gain = information_gain(self.labels, indices)\n",
    "                 \n",
    "                # store the entropy if its the one with the highest gain\n",
    "                if info_gain > highest_gain:\n",
    "                    self.store_split_values(var_index, var_values, indices, info_gain)\n",
    "                    highest_gain = info_gain\n",
    "\n",
    "                    # also store the unique value as the boundary\n",
    "                    self.boundary = unique_value\n",
    "            \n",
    "            # remove the column from the memory\n",
    "            del column\n",
    "                    \n",
    "        \n",
    "    def get_subtree(self, row):\n",
    "        \"\"\" Returns the subtree one branch down, corresponding to the value of\n",
    "            variable in the DataRow for specific variable based on which the split\n",
    "            at this node was performed, and its corresponding boundary.\n",
    "                row - The DataRow object containing the values that are being\n",
    "                        classified\"\"\"\n",
    "        \n",
    "        # get the value of the correct column\n",
    "        value = row.get_numeric(self.var_index)\n",
    "        \n",
    "        # get the branch of that value\n",
    "        if value < self.boundary:\n",
    "            return self.branches['smaller']\n",
    "        else:\n",
    "            return self.branches['bigger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
