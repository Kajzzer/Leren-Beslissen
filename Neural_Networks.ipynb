{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, RNN\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow test\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# # Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "# x_data = np.random.rand(100).astype(np.float32)\n",
    "# y_data = x_data * 0.1 + 0.3\n",
    "# # Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# # (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# # figure that out for us.)\n",
    "# W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "# b = tf.Variable(tf.zeros([1]))\n",
    "# y = W * x_data + b\n",
    "# # Minimize the mean squared errors.\n",
    "# loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "# optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "# train = optimizer.minimize(loss)\n",
    "# # Before starting, initialize the variables.  We will 'run' this first.\n",
    "# init = tf.initialize_all_variables()\n",
    "# # Launch the graph.\n",
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "# # Fit the line.\n",
    "# for step in range(201):\n",
    "#     sess.run(train)\n",
    "#     if step % 20 == 0:\n",
    "#         print(step, sess.run(W), sess.run(b))\n",
    "# # Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras test\n",
    "\n",
    "# '''Trains a simple deep NN on the MNIST dataset.\n",
    "# Gets to 98.40% test accuracy after 20 epochs\n",
    "# (there is *a lot* of margin for parameter tuning).\n",
    "# 2 seconds per epoch on a K520 GPU.\n",
    "# '''\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "# import keras\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.optimizers import RMSprop\n",
    "\n",
    "# batch_size = 128\n",
    "# num_classes = 10\n",
    "# epochs = 20\n",
    "\n",
    "# # the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# print(x_train[0])\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_train /= 255\n",
    "# print(x_train[0])\n",
    "# x_train = x_train.reshape(60000, 784)\n",
    "# x_test = x_test.reshape(10000, 784)\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=RMSprop(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(x_train, y_train,\n",
    "#                     batch_size=batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=(x_test, y_test))\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, let's define a RNN Cell, as a layer subclass.\n",
    "\n",
    "# class MinimalRNNCell(keras.layers.Layer):\n",
    "\n",
    "#     def __init__(self, units, **kwargs):\n",
    "#         self.units = units\n",
    "#         self.state_size = units\n",
    "#         super(MinimalRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "#                                       initializer='uniform',\n",
    "#                                       name='kernel')\n",
    "#         self.recurrent_kernel = self.add_weight(\n",
    "#             shape=(self.units, self.units),\n",
    "#             initializer='uniform',\n",
    "#             name='recurrent_kernel')\n",
    "#         self.built = True\n",
    "\n",
    "#     def call(self, inputs, states):\n",
    "#         prev_output = states[0]\n",
    "#         h = K.dot(inputs, self.kernel)\n",
    "#         output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "#         return output, [output]\n",
    "\n",
    "# # Let's use this cell in a RNN layer:\n",
    "\n",
    "# cell = MinimalRNNCell(32)\n",
    "# x = keras.Input((None, 5))\n",
    "# layer = RNN(cell)\n",
    "# y = layer(x)\n",
    "\n",
    "# # Here's how to use the cell to build a stacked RNN:\n",
    "\n",
    "# cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n",
    "# x = keras.Input((None, 5))\n",
    "# layer = RNN(cells)\n",
    "# y = layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (207, 16)\n"
     ]
    }
   ],
   "source": [
    "x_train_df = pd.read_csv(\"preprocessed_train_split_feat.csv\")\n",
    "print(\"Training data shape:\", x_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (60, 16)\n"
     ]
    }
   ],
   "source": [
    "x_test_df = pd.read_csv(\"preprocessed_validation_split_feat.csv\")\n",
    "\n",
    "print(\"Test data shape:\", x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label shape: (207,)\n"
     ]
    }
   ],
   "source": [
    "y_train_df = pd.read_csv(\"train_split_label.csv\").Label\n",
    "print(\"Training label shape:\", y_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test label shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "y_test_df = pd.read_csv(\"validation_split_label.csv\").Label\n",
    "print(\"Test label shape:\", y_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_rnn_model():\n",
    "#     # Input layers\n",
    "#     teacher_number_of_previously_posted_projects = keras.layers.Input(shape=(1,), name=\"teacher_number_of_previously_posted_projects\")\n",
    "#     project_title = keras.layers.Input(shape=(MAX_PROJECT_TITLE_SEQ_LEN,), name=\"project_title\")\n",
    "#     project_essay = keras.layers.Input(shape=(MAX_PROJECT_ESSAY_SEQ_LEN,), name=\"project_essay\")\n",
    "#     #project_resource_summary = keras.layers.Input(shape=(MAX_PROJECT_RESOURCE_SUMMARY_SEQ_LEN,), name=\"project_resource_summary\")\n",
    "    \n",
    "#     # Embedding layers\n",
    "#     #emb_project_title = keras.layers.Embedding(MAX_PROJECT_TITLE, 25)(project_title)\n",
    "#     #emb_project_essay = keras.layers.Embedding(MAX_PROJECT_ESSAY, 50)(project_essay)\n",
    "#     emb_layer = keras.layers.Embedding(MAX_TEXT, 50)\n",
    "#     emb_project_title = emb_layer(project_title)\n",
    "#     emb_project_essay = emb_layer(project_essay)\n",
    "    \n",
    "#     # RNN layers\n",
    "#     rnn_project_title = keras.layers.GRU(8, activation=\"relu\")(emb_project_title)\n",
    "#     rnn_project_essay = keras.layers.GRU(16, activation=\"relu\")(emb_project_essay)\n",
    "#     #rnn_project_resource_summary = keras.layers.GRU(16, activation=\"relu\")(emb_project_resource_summary)\n",
    "    \n",
    "#     # Merge all layers into one\n",
    "#     x = keras.layers.concatenate([teacher_number_of_previously_posted_projects,\n",
    "#                                  rnn_project_title,\n",
    "#                                  rnn_project_essay,\n",
    "#                                  #rnn_project_resource_summary,\n",
    "#                                  ])\n",
    "    \n",
    "#     # Dense layers\n",
    "#     #x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "#     # Output layers\n",
    "#     output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "#      return keras.models.Model(\n",
    "#         inputs=[teacher_number_of_previously_posted_projects,\n",
    "#                 project_title,\n",
    "#                 project_essay,\n",
    "#                 #project_resource_summary,\n",
    "#                ],\n",
    "#         outputs=output)\n",
    "\n",
    "# rnn_model = create_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaj/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(12, 6), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=2, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(12, 6), random_state=2)\n",
    "\n",
    "clf.fit(x_train_df, y_train_df)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing',\n",
       "       'standing', 'standing', 'standing', 'standing', 'standing'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(x_test_df)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(pred, control):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        total += 1\n",
    "        if pred[i] == control[i]:\n",
    "            correct += 1\n",
    "\n",
    "    print('Accuracy:',correct*100/total,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(pred, y_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
