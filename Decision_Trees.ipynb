{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "## Imports + Turning the labels into numbers for easier classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def numeric_labels(data):\n",
    "    labels = []\n",
    "    for label in data:\n",
    "        if label == 'sitting':\n",
    "            labels.append(0)\n",
    "        elif label == 'lift':\n",
    "            labels.append(1)\n",
    "        elif label =='towlift':\n",
    "            labels.append(2)\n",
    "        elif label =='standing':\n",
    "            labels.append(3)\n",
    "        elif label =='lying':\n",
    "            labels.append(4)\n",
    "        elif label =='snowboarding':\n",
    "            labels.append(5)\n",
    "    return np.asarray(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data and readying variables for training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_split_feat = pd.read_csv(\"preprocessed_train_split_feat.csv\")\n",
    "train_label = pd.read_csv(\"train_split_label.csv\")\n",
    "preprocessed_validation_split_feat= pd.read_csv(\"preprocessed_validation_split_feat.csv\")\n",
    "validation_split_label = pd.read_csv(\"validation_split_label.csv\")\n",
    "pre_test = pd.read_csv(\"preprocessed_test_feat.csv\")\n",
    "test_online = pd.read_csv(\"preprocessed_online_test_feat.csv\")\n",
    "test_label = pd.read_csv(\"test_label.csv\")\n",
    "\n",
    "online_test_label = pd.read_csv(\"online_test_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from id3 import Id3Estimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = preprocessed_train_split_feat\n",
    "y = numeric_labels(train_label.Label)\n",
    "Xt = preprocessed_validation_split_feat\n",
    "control = numeric_labels(validation_split_label.Label)\n",
    "#these are the datasets for the test set\n",
    "X_testing = pre_test\n",
    "y_testing = numeric_labels(test_label.Label)\n",
    "\n",
    "#these are the datasets for the online test set\n",
    "X_test = test_online\n",
    "y_test = numeric_labels(online_test_label.Label)\n",
    "print(X_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using gridsearch to find the best parameters for the ID3 decision tree, training and running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':list(range(1,11)), 'min_samples_split':list(range(1,21)), 'prune':(True, False), 'gain_ratio':(True, False), 'is_repeating':(True, False)}\n",
    "scores= 'accuracy'\n",
    "# clf = GridSearchCV(Id3Estimator(), parameters, cv=5, scoring=scores, n_jobs=-1)\n",
    "clf = Id3Estimator(gain_ratio= True, is_repeating= False, max_depth= 3, min_samples_split= 13, prune = False) \n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "control = y_test\n",
    "pred = clf.predict(X_test)\n",
    "print(accuracy_score(control,pred)* 100)\n",
    "\n",
    "# print(\"Best Score:\", clf.best_score_)\n",
    "# print(\"Best params:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with final data sets (13 metrics) Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics used:\n",
    "#HR,BR,Posture,Activity,PeakAccel,HRConfidence,ROGState,VerticalMin,VerticalPeak,LateralMin,LateralPeak,SagittalMin,SagittalPeak\n",
    "\n",
    "# validation 30.0%\n",
    "# test 48.148148148148145%\n",
    "# online test 56.41025641025641%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set accuracy results ID3 decision tree \n",
    "As stated in our report we thought the accuracy results belonged to the validation set, we later found out these were only tested on the training set itself. We left them for a better view of our process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 16 metrics\n",
    "### HR,BR,Posture,Activity,PeakAccel,ECGAmplitude,ECGNoise,HRConfidence,ROGState,ROGTime,VerticalMin,VerticalPeak,LateralMin,LateralPeak,SagittalMin,SagittalPeak\n",
    "\n",
    "# Best Score: 0.5314009661835749\n",
    "# Best params: {'gain_ratio': False, 'is_repeating': True, 'max_depth': 4, 'min_samples_split': 5, 'prune': True}\n",
    "\n",
    "\n",
    "# Best Score: 0.5314009661835749\n",
    "# Best params: {'gain_ratio': True, 'is_repeating': True, 'max_depth': 7, 'min_samples_split': 12, 'prune': True}\n",
    "\n",
    "# Best Score: 0.5024154589371981\n",
    "# Best params: {'gain_ratio': True, 'is_repeating': True, 'max_depth': 10, 'min_samples_split': 40, 'prune': True}\n",
    "\n",
    "\n",
    "## 4 metrics (hr br posture activity)\n",
    "### HR,BR,Posture,Activity\n",
    "\n",
    "# Best Score: 0.5217391304347826\n",
    "# Best params: {'gain_ratio': False, 'is_repeating': True, 'max_depth': 14, 'min_samples_split': 13, 'prune': True}\n",
    "\n",
    "## 5 metrics\n",
    "### HR,BR,Posture,Activity,PeakAccel\n",
    "\n",
    "# Best Score: 0.5217391304347826\n",
    "# Best params: {'gain_ratio': False, 'is_repeating': True, 'max_depth': 8, 'min_samples_split': 6, 'prune': True}\n",
    "\n",
    "\n",
    "## 11 metrics\n",
    "### HR,BR,Posture,Activity,PeakAccel,VerticalMin,VerticalPeak,LateralMin,LateralPeak,SagittalMin,SagittalPeak\n",
    "\n",
    "# Best Score: 0.5458937198067633\n",
    "# Best params: {'criterion': 'gini', 'max_depth': 3, 'min_impurity_decrease': 0, 'min_samples_split': 2, 'random_state': 2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using gridsearch to find the best parameters for the sklearn decision tree classifier, training and running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':list(range(1,7)), 'min_samples_split':list(range(2,11)), 'min_impurity_decrease':[0, 0.01, 0.1, 0,2, 1], 'random_state':list(range(0,10)), 'criterion':['entropy', 'gini']}\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'prec': 'precision'}\n",
    "clf = tree.DecisionTreeClassifier(criterion= 'gini', max_depth= 5, min_impurity_decrease= 0.01, min_samples_split= 2, random_state= 7)\n",
    "# clf = GridSearchCV(tree.DecisionTreeClassifier(), parameters, cv=5, scoring=scores, n_jobs=-1)\n",
    "clf.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "control = y_test\n",
    "pred_des = clf.predict(X_test)\n",
    "print(accuracy_score(control,pred_des))\n",
    "\n",
    "# print(\"Best Score:\", clf.best_score_)\n",
    "# print(\"Best params:\", clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with final data sets (13 metrics) ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing\n",
    "#HR,BR,Posture,Activity,PeakAccel,HRConfidence,ROGState,VerticalMin,VerticalPeak,LateralMin,LateralPeak,SagittalMin,SagittalPeak\n",
    "\n",
    "# validation 0.26666666666666666%\n",
    "# test 0.4444444444444444%\n",
    "# online test 0.5384615384615384%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set accuracy results SKlearn decision tree classifier\n",
    "As stated in our report we thought the accuracy results belonged to the validation set, we later found out these were only tested on the training set itself. We left them for a better view of our process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 16 metrics\n",
    "### HR,BR,Posture,Activity,PeakAccel,ECGAmplitude,ECGNoise,HRConfidence,ROGState,ROGTime,VerticalMin,VerticalPeak,LateralMin,LateralPeak,SagittalMin,SagittalPeak\n",
    "\n",
    "# Best Score: 0.6280193236714976\n",
    "# Best params: {'criterion': 'entropy', 'max_depth': 3, 'min_impurity_decrease': 0.1, 'min_samples_split': 2, 'random_state': 1}\n",
    "\n",
    "## 12 metrics\n",
    "### \n",
    "# Best Score: 0.5362318840579711\n",
    "# Best params: {'criterion': 'gini', 'max_depth': 5, 'min_impurity_decrease': 0.01, 'min_samples_split': 2, 'random_state': 3}\n",
    "# acc = 0.26666666666666666\n",
    "\n",
    "## 4 metrics \n",
    "### HR,BR,Posture,Activity\n",
    "\n",
    "# Best Score: 0.6183574879227053\n",
    "# Best params: {'criterion': 'entropy', 'max_depth': 5, 'min_impurity_decrease': 0, 'min_samples_split': 2, 'random_state': 5}\n",
    "\n",
    "\n",
    "## 5 metrics\n",
    "### HR,BR,Posture,Activity,PeakAccel\n",
    "\n",
    "# Best Score: 0.5942028985507246\n",
    "# Best params: {'criterion': 'entropy', 'max_depth': 5, 'min_impurity_decrease': 0, 'min_samples_split': 2, 'random_state': 3}\n",
    "\n",
    "\n",
    "## 11 metrics \n",
    "### HR,BR,Posture,Activity,PeakAccel,VerticalMin,VerticalPeak,LateralMin,LateralPeak,SagittalMin,SagittalPeak\n",
    "\n",
    "# Best Score: 0.5458937198067633\n",
    "# Best params: {'criterion': 'gini', 'max_depth': 3, 'min_impurity_decrease': 0, 'min_samples_split': 2, 'random_state': 2}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
